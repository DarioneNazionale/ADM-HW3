{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from the files and witing the the others\n",
    "This code transforms html files to tsv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-b1bd5c441a0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Parsing the html file:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Movies\\\\movie\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".html\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#initialysing variables as NA, so if the sections are missing the variable remains NA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\builder\\_lxml.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleSaxTargetStartNoNs\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._callTargetSaxStart\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\builder\\_lxml.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnsmaps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_NSMAPS_INVERTED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnsmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Make sure attrs is a mutable dict--lxml may send an immutable dictproxy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fileNumber = 0 #starting from file 0\n",
    "while os.path.exists(\"Movies\\\\movie\" + str(fileNumber) + \".html\"): #Iterating for each file \n",
    "    \n",
    "    #Parsing the html file:\n",
    "    with open(\"Movies\\\\movie\" + str(fileNumber) + \".html\", 'rb') as html:\n",
    "        soup = BeautifulSoup(html)\n",
    "    \n",
    "    #initialysing variables as NA, so if the sections are missing the variable remains NA \n",
    "    title = \"NA\"\n",
    "    intro = \"NA\"\n",
    "    plot = \"NA\"\n",
    "    infobox = OrderedDict() #we must put as key of the dict the keyword that we will find in the infobox of wikipedia:\n",
    "    infobox[\"name\"] = \"NA\"\n",
    "    infobox[\"Directed by\"] = \"NA\"\n",
    "    infobox[\"Produced by\"] = \"NA\"\n",
    "    infobox[\"Written by\"] = \"NA\"\n",
    "    infobox[\"Starring\"] = \"NA\"\n",
    "    infobox[\"Music by\"] = \"NA\"\n",
    "    infobox[\"Release date\"] = \"NA\"\n",
    "    infobox[\"Running time\"] = \"NA\"\n",
    "    infobox[\"Country\"] = \"NA\"\n",
    "    infobox[\"Language\"] = \"NA\"\n",
    "    infobox[\"Budget\"] = \"NA\"\n",
    "    \n",
    "    \n",
    "    #-------------------------- Title, Intro and Plot code ----------------------------------------\n",
    "    title = soup.title.string.strip(\" - Wikipedia\") #taking the title, without the \" - Wikipedia\" last part.\n",
    "\n",
    "    body = soup.body #put the soup body in a variable.\n",
    "    paragraphNumber = 1 #a counter for know whitch paragraf are we working on \n",
    "    for paragraph in body.find_all('p'): #iterating on the paragrafs \n",
    "        if(paragraphNumber == 1):#putting the first paragraf in the intro variable\n",
    "            intro = paragraph.text.strip() #using strip to delete space characters\n",
    "            paragraphNumber += 1\n",
    "        elif(paragraphNumber == 2):#putting the second paragraf in the plot variable\n",
    "            plot = paragraph.text.strip() #using strip to delete space characters\n",
    "            break #we don't need the other paragrafs\n",
    "    #-------------------------- Title, Intro and Plot code ----------------------------------------\n",
    "    \n",
    "\n",
    "    #-------------------------- Infobox code ----------------------------------------\n",
    "    table = soup.find('table', class_='infobox vevent')\n",
    "\n",
    "    try:\n",
    "        infobox[\"name\"] = table.find('tr').text #let's search the infobox\n",
    "        for tr in table.find_all('tr'): #for each content in the infobox\n",
    "            for section in infobox.keys(): #check for each content that we need...\n",
    "                try: \n",
    "                    if section == tr.find('th').text: #check if the current tr is the section that we wont\n",
    "                        infobox[section] = tr.find('td').text.strip() #if it is, save it in the infobox[section]\n",
    "                except: pass #if it is an empty tag\n",
    "    except: pass #if the infobox is not in the page \n",
    "    #-------------------------- Infobox code ----------------------------------------\n",
    "\n",
    "    \n",
    "    #-------------------------- Writing on the file ----------------------------------------\n",
    "    #this lines create a new directory, Movies, in your project folder\n",
    "    if not os.path.exists(\"MoviesTSV\\\\\"):\n",
    "        os.makedirs(\"MoviesTSV\\\\\")\n",
    "    \n",
    "    #writing the results in the tsv file \n",
    "    with open('MoviesTSV\\\\article_' + str(fileNumber) + '.tsv', 'wt', encoding = 'utf-8') as out_file: #creating one file for each different movie \n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        tsv_writer.writerow([title, intro, plot] + list(infobox.values())) #input to the tsv file.\n",
    "        #tsv_writer.writerow(list(map(lambda x: x.encode('utf-8'), [title, intro, plot] + list(infobox.values())))) #input to the tsv file.\n",
    "    #-------------------------- Writing on the file ----------------------------------------\n",
    "    \n",
    "    fileNumber += 1 #let's move to the next file!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
