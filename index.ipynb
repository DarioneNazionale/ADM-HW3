{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### just libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to preprocess\n",
    "remove punctuation, stop words and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    \n",
    "    #Remove punctuation and lower all characters\n",
    "    words = nltk.word_tokenize(s)\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "    \n",
    "    #Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [i for i in words if i not in stop_words]\n",
    "    \n",
    "    #Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### working on all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-489e4a18a7af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfileNumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m#starting from file 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MoviesTSV\\\\article_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".tsv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#Iterating for each file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MoviesTSV\\\\article_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "vocabulary = dict()\n",
    "indexDictionary = defaultdict(list)\n",
    "\n",
    "fileNumber = 0  # starting from file 0\n",
    "while os.path.exists(\"MoviesTSV\\\\article_\" + str(fileNumber) + \".tsv\"):  # Iterating for each file\n",
    "    with open('MoviesTSV\\\\article_' + str(fileNumber) + '.tsv', encoding='utf8') as tsvfile:\n",
    "\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        row = next(reader)\n",
    "\n",
    "        plot = row[1]\n",
    "        intro = row[2]\n",
    "\n",
    "        preprocessed_data = preprocess(intro + plot)\n",
    "\n",
    "\n",
    "        if len(vocabulary.keys()) == 0:\n",
    "            vocabulary = dict([(x + 1, y) for x, y in enumerate(sorted(set(preprocessed_data)))])\n",
    "        else:\n",
    "            for word in preprocessed_data:\n",
    "                if not word in vocabulary.values():\n",
    "                    vocabulary[max(vocabulary.keys())] = word\n",
    "\n",
    "        for index in vocabulary:\n",
    "            if vocabulary[index] in preprocessed_data:\n",
    "                indexDictionary[index].append(fileNumber)\n",
    "\n",
    "        fileNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "search = input() #taken search elements from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfsearchElements = search.split()\n",
    "listOfsearchElements = list(dict.fromkeys(listOfsearchElements)) #removing repeating elements in a list\n",
    "\n",
    "keyList=[] \n",
    "resultlist = []\n",
    "\n",
    "listOfTitle= []\n",
    "listOfIntro= []\n",
    "listOfUrl=[]\n",
    "\n",
    "for i in range(len(listOfsearchElements)):\n",
    "    for (key, value) in vocabulary.items():\n",
    "        if value == listOfsearchElements[i]: #check the search elements are in vocabulary dictionary , or not ?\n",
    "            keyList.append(key) #if they are exist in vocabulary dictionary , up them on keyList \n",
    "\n",
    "if(len(keyList) != len(listOfsearchElements)): # Being \"len of key isnt equal to len of search list\" mean is we cant research for all search element, so just quit to search\n",
    "    print(\"Opps! Sorry we can't find any film\")\n",
    "\n",
    "\n",
    "if(len(keyList) == len(listOfsearchElements)):\n",
    "    \n",
    "    for j in range(len(keyList)):\n",
    "        for (key, value) in indexDictionary.items():\n",
    "            if key == keyList[j]:\n",
    "                resultlist.append(value)\n",
    "                \n",
    "#compare for common articles\n",
    "result = set(resultlist[0])\n",
    "for s in resultlist[1:]:\n",
    "    result.intersection_update(s)\n",
    "\n",
    "result = list(result)\n",
    "for i in range(len(result)):\n",
    "    with open('MoviesTSV\\\\article_' + str(i) + '.tsv', encoding='utf8') as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        row = next(reader)\n",
    "\n",
    "        title = row[0]\n",
    "        intro = row[1]\n",
    "        url = row[4]\n",
    "\n",
    "        listOfTitle.append(title)\n",
    "        listOfIntro.append(intro)\n",
    "        listOfUrl.append(url)\n",
    "        movies_df = pd.DataFrame({'Title': listOfTitle, 'Intro': intro,'Url': url})\n",
    "print(movies_df)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
